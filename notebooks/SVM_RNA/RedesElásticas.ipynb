{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fb8e8eb",
   "metadata": {},
   "source": [
    "### **CÉLULA 1: IMPORTAÇÃO DE BIBLIOTECAS**\n",
    "\n",
    "Nesta célula, importamos todas as bibliotecas necessárias para a análise e construção dos modelos de Machine Learning. Cada biblioteca tem uma função específica:\n",
    "\n",
    "*   **`pandas` (pd)**: Utilizada para manipulação e análise de dados, especialmente DataFrames.\n",
    "*   **`numpy` (np)**: Fundamental para operações numéricas e matemáticas de alto desempenho.\n",
    "*   **`matplotlib.pyplot` (plt)** e **`seaborn` (sns)**: Usadas para visualização de dados e criação de gráficos estatísticos.\n",
    "*   **`sklearn.model_selection.train_test_split`**: Para dividir os dados em conjuntos de treinamento e teste.\n",
    "*   **`sklearn.preprocessing.LabelEncoder`** e **`StandardScaler`**: Para transformar variáveis categóricas em numéricas e para normalizar as features — etapa **obrigatória** para SVM e RNA, que são sensíveis à escala dos dados.\n",
    "*   **`sklearn.svm.SVC`**: O algoritmo **Support Vector Machine** (Classificador).\n",
    "*   **`sklearn.neural_network.MLPClassifier`**: O algoritmo de **Rede Neural Artificial** (Perceptron Multi-Camadas).\n",
    "*   **`sklearn.metrics`**: Contém funções para avaliar o desempenho dos modelos (acurácia, precisão, recall, F1-Score e matriz de confusão).\n",
    "*   **`sklearn.inspection.permutation_importance`**: Usada para calcular a importância das features de forma agnóstica ao modelo.\n",
    "\n",
    "O `sns.set(style=\"whitegrid\")` configura um estilo padrão para os gráficos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbfca68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# CÉLULA 1: IMPORTAÇÃO DE BIBLIOTECAS\n",
    "# ==============================================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Bibliotecas de Machine Learning (Scikit-Learn)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
    "                             f1_score, confusion_matrix, classification_report)\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# Configuração de estilo dos gráficos\n",
    "sns.set(style=\"whitegrid\")\n",
    "print(\"Bibliotecas importadas com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832df994",
   "metadata": {},
   "source": [
    "### **CÉLULA 2: CARREGAMENTO E VISUALIZAÇÃO DOS DADOS**\n",
    "\n",
    "Esta célula é responsável por carregar o conjunto de dados (`baseMLJurandir.csv`) em um DataFrame do pandas. Após o carregamento, exibimos as primeiras 5 linhas (`df.head()`) para ter uma visão inicial dos dados e confirmamos suas dimensões (`df.shape`).\n",
    "\n",
    "Um bloco `try-except` é usado para lidar com a situação em que o arquivo não é encontrado, fornecendo uma mensagem de erro útil para o usuário."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d182771d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# CÉLULA 2: CARREGAMENTO E VISUALIZAÇÃO DOS DADOS\n",
    "# ==============================================================================\n",
    "try:\n",
    "    df = pd.read_csv('baseMLJurandir.csv')\n",
    "    print(f\"Dataset carregado com sucesso! Dimensões: {df.shape}\")\n",
    "    display(df.head())\n",
    "except FileNotFoundError:\n",
    "    print(\"ERRO: O arquivo 'baseMLJurandir.csv' não foi encontrado.\")\n",
    "    print(\"Por favor, faça o upload do arquivo na aba de arquivos à esquerda ou verifique o caminho.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61cd6de",
   "metadata": {},
   "source": [
    "### **CÉLULA 3: PRÉ-PROCESSAMENTO E ENGENHARIA DE FEATURES**\n",
    "\n",
    "Esta é uma etapa crucial para preparar os dados para o treinamento do modelo. Realizamos diversas transformações:\n",
    "\n",
    "1.  **Correção de Colunas com Erro de Encoding**: Muitas vezes, caracteres especiais (como `ú` ou `ção`) podem ser carregados incorretamente (ex: `Ãºcleo`, `Ã§Ã£o`). Criamos uma função auxiliar (`corrigir_coluna`) para identificar e renomear essas colunas para seus nomes corretos (`núcleo`, `modulação`), garantindo que o código possa referenciá-las corretamente.\n",
    "\n",
    "2.  **Criação da Variável Target (`aceito`)**: A coluna original `resultado` é usada para criar uma nova variável binária chamada `aceito`. Se `resultado` for `1`, `aceito` é `1` (indicando que o circuito foi aceito); caso contrário, `aceito` é `0` (indicando bloqueio). Esta será a variável que nossos modelos tentarão prever.\n",
    "\n",
    "3.  **Remoção da Coluna Original `resultado`**: Após criar `aceito`, a coluna `resultado` se torna redundante e é removida do DataFrame.\n",
    "\n",
    "4.  **Criação da Feature `slots_usados`**: Duas colunas existentes, `primeiro slot` e `ultimo slot`, são combinadas para criar uma nova e mais informativa feature, `slots_usados`, que representa a quantidade de slots utilizados. As colunas originais são então removidas.\n",
    "\n",
    "5.  **Tratamento da Variável Categórica `modulação`**: A coluna `modulação` é uma variável categórica. Para que os algoritmos de Machine Learning possam processá-la, ela é convertida em um formato numérico usando `LabelEncoder`.\n",
    "\n",
    "Ao final, exibimos a estrutura do DataFrame processado e suas colunas para verificar as mudanças."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fcd23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# CÉLULA 3: PRÉ-PROCESSAMENTO E ENGENHARIA DE FEATURES\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"Colunas do DataFrame antes do pré-processamento:\", df.columns.tolist())\n",
    "\n",
    "# --- Correção de Colunas com Erro de Encoding ---\n",
    "def corrigir_coluna(df, prefixo_esperado, sufixos_erro, nome_correto):\n",
    "    found_col = None\n",
    "    for col in df.columns:\n",
    "        if prefixo_esperado in col.lower():\n",
    "            for sufixo in sufixos_erro:\n",
    "                if sufixo in col:\n",
    "                    found_col = col\n",
    "                    break\n",
    "            if found_col:\n",
    "                break\n",
    "\n",
    "    if found_col and found_col != nome_correto:\n",
    "        df.rename(columns={found_col: nome_correto}, inplace=True)\n",
    "        print(f\"Coluna '{found_col}' renomeada para '{nome_correto}'.\")\n",
    "    elif found_col and found_col == nome_correto:\n",
    "        print(f\"Coluna '{nome_correto}' já está com o nome correto.\")\n",
    "    else:\n",
    "        print(f\"AVISO: A coluna '{nome_correto}' (ou sua variação com encoding errado) não foi encontrada no DataFrame.\")\n",
    "\n",
    "# Corrigir 'núcleo'\n",
    "corrigir_coluna(df, 'n', ['Ãºcleo'], 'núcleo')\n",
    "\n",
    "# Corrigir 'modulação'\n",
    "corrigir_coluna(df, 'modula', ['Ã§Ã£o', 'ção'], 'modulação')\n",
    "# --- Fim da Correção de Colunas ---\n",
    "\n",
    "# 1. Criar variável target binária \"aceito\"\n",
    "df['aceito'] = df['resultado'].apply(lambda x: 1 if x == 1 else 0)\n",
    "\n",
    "# 2. Remover a coluna original \"resultado\"\n",
    "df.drop('resultado', axis=1, inplace=True)\n",
    "\n",
    "# 3. Criar feature \"slots_usados\" e remover \"primeiro slot\" e \"ultimo slot\"\n",
    "df['slots_usados'] = df['ultimo slot'] - df['primeiro slot'] + 1\n",
    "df.drop(['primeiro slot', 'ultimo slot'], axis=1, inplace=True)\n",
    "\n",
    "# 4. Tratar variável categórica \"modulação\" com LabelEncoder\n",
    "le = LabelEncoder()\n",
    "if 'modulação' in df.columns and df['modulação'].dtype == 'object':\n",
    "    df['modulação'] = le.fit_transform(df['modulação'])\n",
    "    print(\"Classes de modulação codificadas:\", list(le.classes_))\n",
    "elif 'modulação' in df.columns:\n",
    "    print(\"A coluna 'modulação' já parece ser numérica ou foi convertida, nenhuma alteração feita.\")\n",
    "else:\n",
    "    print(\"ERRO: A coluna 'modulação' não foi encontrada no DataFrame após a tentativa de correção.\")\n",
    "\n",
    "print(\"\\n--- Estrutura Final do Dataset ---\")\n",
    "display(df.head())\n",
    "print(f\"Colunas finais: {df.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4d6aeb",
   "metadata": {},
   "source": [
    "### **CÉLULA 4: SEPARAÇÃO EM TREINO E TESTE**\n",
    "\n",
    "Para avaliar corretamente o desempenho de um modelo de Machine Learning, é fundamental dividirmos o conjunto de dados em duas partes:\n",
    "\n",
    "*   **Conjunto de Treino (Training Set)**: Usado para treinar o modelo, ou seja, para que ele aprenda os padrões nos dados.\n",
    "*   **Conjunto de Teste (Test Set)**: Usado para avaliar o desempenho do modelo em dados *nunca antes vistos*. Isso nos ajuda a ter uma ideia de como o modelo se comportará em situações reais e a evitar o *overfitting*.\n",
    "\n",
    "Aqui, utilizamos `train_test_split` para separar os dados em **70% para treino** e **30% para teste**. O parâmetro `random_state=42` garante reprodutibilidade dos resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bc2751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# CÉLULA 4: SEPARAÇÃO EM TREINO E TESTE\n",
    "# ==============================================================================\n",
    "\n",
    "# Definir X (features) e y (target)\n",
    "X = df.drop('aceito', axis=1)\n",
    "y = df['aceito']\n",
    "\n",
    "# Separar: 70% Treino, 30% Teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "\n",
    "print(f\"Tamanho do Treino: {X_train.shape[0]} amostras\")\n",
    "print(f\"Tamanho do Teste:  {X_test.shape[0]} amostras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea57fa24",
   "metadata": {},
   "source": [
    "### **CÉLULA 5: NORMALIZAÇÃO DAS FEATURES (StandardScaler)**\n",
    "\n",
    "Esta etapa é **exclusiva e obrigatória** para os algoritmos SVM e RNA, sendo desnecessária no Random Forest (que é invariante à escala).\n",
    "\n",
    "#### **Por que escalar os dados?**\n",
    "\n",
    "*   **SVM**: O algoritmo busca o hiperplano de margem máxima entre as classes. Se as features tiverem escalas muito diferentes (ex: uma feature varia de 0 a 1000 e outra de 0 a 1), a que tem maior magnitude dominará o cálculo da distância, distorcendo completamente o hiperplano ótimo.\n",
    "\n",
    "*   **RNA (MLPClassifier)**: A Rede Neural usa gradiente descendente para otimizar os pesos. Com features em escalas díspares, o gradiente se torna excessivamente assimétrico, causando convergência lenta ou instável.\n",
    "\n",
    "#### **Como funciona o `StandardScaler`?**\n",
    "\n",
    "Ele transforma cada feature para ter **média 0** e **desvio padrão 1** (padronização Z-score):\n",
    "\n",
    "$$z = \\frac{x - \\mu}{\\sigma}$$\n",
    "\n",
    "**Regra de ouro**: O scaler é ajustado (`fit`) **apenas nos dados de treino** para evitar *data leakage*. Em seguida, é aplicado (`transform`) tanto no treino quanto no teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cff14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# CÉLULA 5: NORMALIZAÇÃO DAS FEATURES (StandardScaler)\n",
    "# ==============================================================================\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# IMPORTANTE: fit() apenas no treino para evitar data leakage\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled  = scaler.transform(X_test)\n",
    "\n",
    "print(\"Normalização concluída com StandardScaler.\")\n",
    "print(f\"Média das features (treino após scaling): {X_train_scaled.mean(axis=0).round(4)}\")\n",
    "print(f\"Desvio padrão (treino após scaling):      {X_train_scaled.std(axis=0).round(4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3de73c",
   "metadata": {},
   "source": [
    "### **CÉLULA 6: TREINAMENTO DOS MODELOS**\n",
    "\n",
    "Nesta célula, inicializamos e treinamos dois modelos de classificação:\n",
    "\n",
    "1.  **Support Vector Machine (SVC)**: Algoritmo que busca o hiperplano de margem máxima que separa as classes no espaço de features. Utilizamos o **kernel RBF** (*Radial Basis Function*), que projeta os dados em um espaço de dimensão superior — permitindo separar classes que não são linearmente separáveis no espaço original. Os parâmetros principais são:\n",
    "    *   `C=1.0` — parâmetro de regularização (penalidade por erros de classificação). Valores maiores = margem menor e menos erros no treino.\n",
    "    *   `kernel='rbf'` — tipo de kernel utilizado.\n",
    "    *   `gamma='scale'` — define o alcance de influência de cada amostra de treino.\n",
    "    *   `probability=True` — habilita a estimativa de probabilidades (necessário para alguns contextos).\n",
    "\n",
    "2.  **RNA — Rede Neural Artificial (MLPClassifier)**: Implementa um Perceptron Multi-Camadas com backpropagation. A arquitetura definida é:\n",
    "    *   `hidden_layer_sizes=(100, 50)` — duas camadas ocultas com 100 e 50 neurônios, respectivamente.\n",
    "    *   `activation='relu'` — função de ativação ReLU nas camadas ocultas.\n",
    "    *   `solver='adam'` — otimizador Adam, eficiente para grandes conjuntos de dados.\n",
    "    *   `max_iter=500` — número máximo de épocas de treinamento.\n",
    "    *   `random_state=42` — garante reprodutibilidade.\n",
    "\n",
    "Ambos os modelos são treinados (`.fit()`) usando os dados **normalizados** de treino (`X_train_scaled`, `y_train`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a4b3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# CÉLULA 6: TREINAMENTO DOS MODELOS\n",
    "# ==============================================================================\n",
    "\n",
    "# 1. Support Vector Machine (SVC com kernel RBF)\n",
    "svm_model = SVC(C=1.0, kernel='rbf', gamma='scale', probability=True, random_state=42)\n",
    "svm_model.fit(X_train_scaled, y_train)\n",
    "print(\"Modelo SVM (kernel RBF) treinado.\")\n",
    "print(f\"  Número de vetores de suporte por classe: {svm_model.n_support_}\")\n",
    "\n",
    "# 2. Rede Neural Artificial (MLP - Perceptron Multi-Camadas)\n",
    "rna_model = MLPClassifier(\n",
    "    hidden_layer_sizes=(100, 50),\n",
    "    activation='relu',\n",
    "    solver='adam',\n",
    "    max_iter=500,\n",
    "    random_state=42,\n",
    "    early_stopping=True,\n",
    "    validation_fraction=0.1,\n",
    "    n_iter_no_change=15\n",
    ")\n",
    "rna_model.fit(X_train_scaled, y_train)\n",
    "print(f\"\\nModelo RNA (MLP) treinado.\")\n",
    "print(f\"  Camadas: {rna_model.n_layers_} | Iterações realizadas: {rna_model.n_iter_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43b0980",
   "metadata": {},
   "source": [
    "### **CÉLULA 7: AVALIAÇÃO DOS MODELOS**\n",
    "\n",
    "Após treinar os modelos, avaliamos seu desempenho com uma função auxiliar `avaliar_modelo` que calcula métricas e exibe a matriz de confusão.\n",
    "\n",
    "#### **Métricas de Avaliação:**\n",
    "\n",
    "*   **Acurácia (Accuracy)**: Proporção de previsões corretas sobre o total.\n",
    "*   **Precisão (Precision)**: Das previsões positivas, quantas estavam corretas? Minimiza **falsos positivos** (circuito bloqueado previsto como aceito).\n",
    "*   **Recall (Sensibilidade)**: Dos casos realmente positivos, quantos foram identificados? Minimiza **falsos negativos** (circuito válido previsto como bloqueio). Um **alto Recall** para `aceito=1` significa que o modelo não bloqueia erroneamente circuitos válidos.\n",
    "*   **F1-Score**: Média harmônica entre Precisão e Recall. Útil em datasets desbalanceados.\n",
    "\n",
    "#### **Matriz de Confusão:**\n",
    "\n",
    "Mostra a distribuição de:\n",
    "*   **VP** — Previu Aceito, era Aceito.\n",
    "*   **VN** — Previu Bloqueio, era Bloqueio.\n",
    "*   **FP** — Previu Aceito, era Bloqueio (circuito bloqueado aceito erroneamente).\n",
    "*   **FN** — Previu Bloqueio, era Aceito (circuito válido bloqueado erroneamente).\n",
    "\n",
    "O `classification_report` fornece um resumo detalhado por classe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0e4a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# CÉLULA 7: AVALIAÇÃO DOS MODELOS\n",
    "# ==============================================================================\n",
    "\n",
    "def avaliar_modelo(modelo, nome_modelo, X_test_s, y_test):\n",
    "    \"\"\"Função auxiliar para calcular métricas e plotar matriz de confusão.\"\"\"\n",
    "    y_pred = modelo.predict(X_test_s)\n",
    "\n",
    "    # Métricas\n",
    "    acc  = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred)\n",
    "    rec  = recall_score(y_test, y_pred)\n",
    "    f1   = f1_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"--- Resultados: {nome_modelo} ---\")\n",
    "    print(f\"Acurácia:  {acc:.4f}\")\n",
    "    print(f\"Precision: {prec:.4f}\")\n",
    "    print(f\"Recall:    {rec:.4f}\")\n",
    "    print(f\"F1-Score:  {f1:.4f}\")\n",
    "    print(\"\\nRelatório de Classificação:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    # Matriz de Confusão\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "    plt.title(f'Matriz de Confusão — {nome_modelo}')\n",
    "    plt.xlabel('Predito (0=Bloqueio, 1=Aceito)')\n",
    "    plt.ylabel('Real (0=Bloqueio, 1=Aceito)')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return [acc, prec, rec, f1]\n",
    "\n",
    "# Avaliar SVM\n",
    "metrics_svm = avaliar_modelo(svm_model, \"SVM (kernel RBF)\", X_test_scaled, y_test)\n",
    "\n",
    "# Avaliar RNA\n",
    "metrics_rna = avaliar_modelo(rna_model, \"RNA (MLP)\", X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c3b3cb",
   "metadata": {},
   "source": [
    "### **CÉLULA 8: COMPARAÇÃO FINAL DOS MODELOS**\n",
    "\n",
    "Nesta célula, consolidamos as métricas de avaliação de ambos os modelos (SVM e RNA) em um DataFrame para facilitar a comparação lado a lado. Em seguida, visualizamos essas métricas com um gráfico de barras comparativo.\n",
    "\n",
    "Essa comparação é fundamental para escolher o modelo mais adequado para implantação, levando em conta os objetivos do negócio — por exemplo, se é mais crítico minimizar falsos negativos (circuitos válidos bloqueados) ou falsos positivos (circuitos inválidos aceitos)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e47a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# CÉLULA 8: COMPARAÇÃO FINAL DOS MODELOS\n",
    "# ==============================================================================\n",
    "\n",
    "# Criar DataFrame comparativo\n",
    "df_compare = pd.DataFrame({\n",
    "    'Métrica':  ['Acurácia', 'Precision', 'Recall', 'F1-Score'],\n",
    "    'SVM (RBF)': metrics_svm,\n",
    "    'RNA (MLP)': metrics_rna\n",
    "})\n",
    "\n",
    "print(\"\\n--- Comparação Lado a Lado ---\")\n",
    "display(df_compare)\n",
    "\n",
    "# Gráfico de barras comparativo\n",
    "df_compare_melted = df_compare.melt(id_vars=\"Métrica\", var_name=\"Modelo\", value_name=\"Valor\")\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=\"Métrica\", y=\"Valor\", hue=\"Modelo\", data=df_compare_melted, palette=\"magma\")\n",
    "plt.title(\"Comparação de Desempenho: SVM vs RNA (MLP)\")\n",
    "plt.ylim(0, 1.1)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee30ae28",
   "metadata": {},
   "source": [
    "### **CÉLULA 9: IMPORTÂNCIA DAS FEATURES (Permutation Importance)**\n",
    "\n",
    "Diferentemente do Random Forest, que possui importância de features nativa (`feature_importances_`), o **SVM** e a **RNA não oferecem esse atributo diretamente**. Para contornar essa limitação, usamos a técnica de **Permutation Importance** (`sklearn.inspection.permutation_importance`).\n",
    "\n",
    "#### **Como funciona a Permutation Importance?**\n",
    "\n",
    "O método avalia a queda no desempenho do modelo quando os valores de uma feature são aleatoriamente permutados (embaralhados) no conjunto de teste:\n",
    "\n",
    "1.  Calcula a métrica base do modelo (acurácia) no conjunto de teste original.\n",
    "2.  Para cada feature, embaralha seus valores e calcula novamente a métrica.\n",
    "3.  A **importância** é a diferença entre a métrica original e a métrica após o embaralhamento.\n",
    "\n",
    "**Interpretação**: Se embaralhar uma feature causa grande queda na acurácia, essa feature é muito importante para o modelo. Se a queda for pequena (ou nula), a feature é pouco relevante.\n",
    "\n",
    "Esta abordagem é **agnóstica ao modelo** — funciona igualmente para SVM, RNA, Random Forest ou qualquer outro algoritmo, tornando as comparações entre modelos mais justas.\n",
    "\n",
    "O gráfico mostra os resultados para ambos os modelos lado a lado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b929bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# CÉLULA 9: IMPORTÂNCIA DAS FEATURES (Permutation Importance)\n",
    "# ==============================================================================\n",
    "\n",
    "feature_names = X.columns.tolist()\n",
    "\n",
    "def plotar_permutation_importance(modelo, nome_modelo, X_test_s, y_test, feature_names, color):\n",
    "    result = permutation_importance(\n",
    "        modelo, X_test_s, y_test,\n",
    "        n_repeats=30,\n",
    "        random_state=42,\n",
    "        scoring='accuracy'\n",
    "    )\n",
    "    sorted_idx = result.importances_mean.argsort()[::-1]\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(\n",
    "        range(len(feature_names)),\n",
    "        result.importances_mean[sorted_idx],\n",
    "        xerr=result.importances_std[sorted_idx],\n",
    "        align='center',\n",
    "        color=color,\n",
    "        alpha=0.85\n",
    "    )\n",
    "    plt.yticks(range(len(feature_names)), [feature_names[i] for i in sorted_idx])\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.xlabel(\"Queda média na acurácia (maior = mais importante)\")\n",
    "    plt.title(f\"Permutation Importance — {nome_modelo}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    df_imp = pd.DataFrame({\n",
    "        'Feature': [feature_names[i] for i in sorted_idx],\n",
    "        'Importância Média': result.importances_mean[sorted_idx].round(4),\n",
    "        'Desvio Padrão':     result.importances_std[sorted_idx].round(4)\n",
    "    })\n",
    "    display(df_imp)\n",
    "\n",
    "print(\"Calculando Permutation Importance para o SVM...\")\n",
    "plotar_permutation_importance(svm_model, \"SVM (kernel RBF)\", X_test_scaled, y_test, feature_names, color=\"steelblue\")\n",
    "\n",
    "print(\"\\nCalculando Permutation Importance para a RNA (MLP)...\")\n",
    "plotar_permutation_importance(rna_model, \"RNA (MLP)\", X_test_scaled, y_test, feature_names, color=\"coral\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
